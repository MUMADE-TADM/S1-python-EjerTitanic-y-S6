{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUMADE-TADM/S1-python-y-S5-Titanic-/blob/main/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_kY8a5rr5qC"
      },
      "source": [
        "[Yahoo finance](https://finance.yahoo.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3zKcC8XtEnq"
      },
      "outputs": [],
      "source": [
        "!pip install -U yfinance pandas_datareader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mad_HUVxyXd"
      },
      "source": [
        "# Datos: valor de cierre del IBEX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxaB4kY0tofH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBeJELUotfza"
      },
      "outputs": [],
      "source": [
        "yf.pdr_override() # <== that's all it takes :-)\n",
        "data = pdr.get_data_yahoo(\"^IBEX\", start=\"2020-01-01\", end=\"2020-10-30\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3UO3lLZvASE"
      },
      "source": [
        "## [Bollinger Bands](https://en.wikipedia.org/wiki/Bollinger_Bands):\n",
        "\n",
        "El 97% de los valores de un activo se encuentran entre un máximo de $+1.96 \\times  \\sigma(20\\ valores\\ anteriores)$ y $-1.96 \\times \\sigma(20\\ valores\\  anteriores)$ centrados en la media de los 20 valores anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz2OmhmRt4n4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "d=pd.DataFrame()\n",
        "d['R']=data['Close']\n",
        "d['M']=data['Close'].rolling(20).mean()\n",
        "d['+M']=d['M']+data['Close'].rolling(20).std()*1.96\n",
        "d['-M']=d['M']-data['Close'].rolling(20).std()*1.96\n",
        "d.plot(figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4g6TlcVyfex"
      },
      "source": [
        "## Transformación de los datos para un problema de regresión / clasificación:\n",
        "- Datos originales $[c_0,\\ldots,c_T]$.\n",
        "- Datos transformados:$[[c_0,\\ldots,c_{19}],c_{20}],\\ldots,[[c_{T-20},\\ldots,c_{T-1}],c_T]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTbZ91vZ9tiv"
      },
      "outputs": [],
      "source": [
        "def windowData(s,window_input=1,window_output=1,step=1):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  #Datos necesarios:\n",
        "  dn=window_input+window_output\n",
        "  #Calcular cuantos pasos completos podemos realizar, sin contar el último bloque [input,output].\n",
        "  ld=int((len(s)-dn)/step)*step\n",
        "  for i in range(len(s)-ld-1,len(s)-dn,step):\n",
        "    X.append(s[i:i+window_input])\n",
        "    Y.append(s[i+window_input:i+dn])\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkai0YWG1QiW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Escalanos los datos:\n",
        "dScale = MinMaxScaler()\n",
        "ldatos=d['R'].values #ldatos.shape=(len(d['R']),).\n",
        "ldatos=ldatos.reshape((len(d['R']),1)) #ldatos.shape=(len(d['R']),1).\n",
        "dScale.fit(ldatos)\n",
        "ldatos=dScale.transform(ldatos).reshape((len(ldatos),))\n",
        "\n",
        "#Contruimos los conjunto de datos X e Y:\n",
        "X,Y=windowData(ldatos,window_input=20,window_output=1,step=1)\n",
        "X=np.array(X)\n",
        "Y=np.array(Y)\n",
        "\n",
        "#Patimos los conjuntos en entranamiento y test:\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33,shuffle=False, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhj2JGaa2r9k"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KjokLBm2r9k"
      },
      "source": [
        "## Ajustamos los datos!!\n",
        "Los datos en las **redes recurrentes** son tensores de 3 dimensiones\n",
        "\\[número de ejemplos por batch, tamaño del paso (tamaño del dataset), número de características \\].\n",
        "\n",
        "**\\[size,step,features\\] !!**\n",
        "\n",
        "Consideramos un **step** de 20 con una única **característica** (cant. de parámetros que queremos tener).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jByCKKTV2r9k"
      },
      "outputs": [],
      "source": [
        "XRNN=X.reshape((X.shape[0],X.shape[1],1))\n",
        "XRNN.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4iLDwKJpKIq"
      },
      "source": [
        "## Librerías necesarias:\n",
        "- [Keras](https://keras.io/).\n",
        "- [Tensorflow](https://www.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcunIHLYpodt"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Input,SimpleRNN\n",
        "from tensorflow.keras import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdDwd3YiqiPw"
      },
      "source": [
        "## Definimos la Red:\n",
        "\n",
        "Definimos nuestro perceptron con las siguientes capas (**layers**):\n",
        "- Modelo secuencial [Sequential](https://keras.io/api/models/sequential/).\n",
        "- Capa de entrada: [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/).\n",
        "- Capa Densa: [Dense](https://keras.io/api/layers/core_layers/dense/).\n",
        "\n",
        "La capa **SimpleRNN** define una unidad recurente con **unit** neuronas de salida y una entrada de **input_shape**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPV1HOI2r9l"
      },
      "source": [
        "**Recurrente básica :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X66tPmc2r9l"
      },
      "outputs": [],
      "source": [
        "#Definimos nuestro modelo y vamos añadiendo capas. \n",
        "rnn = Sequential() \n",
        "rnn.add(SimpleRNN(units=32, activation=\"relu\",input_shape=(20,1))) #units=32 -> significa que la salida de esta capa va a ser 32. \n",
        "rnn.add(Dense(1))\n",
        "rnn.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las *va* empaquetadas de las diapos tienen un valor de  1088."
      ],
      "metadata": {
        "id": "SnaM1289-_Yc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_nr6THhu79F"
      },
      "source": [
        "## Compilamos la red:\n",
        "Definido el **perceptrón** lo tendremos que compilar indicando:\n",
        "- Que optimizador utilizar.\n",
        "- Que función de error (pérdida o **loss**).\n",
        "- Que métricas observar cuando lo entrenemos.\n",
        "\n",
        "Función [**compile**](https://keras.io/api/models/model_training_apis/#compile-method)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJqvqoKLqrMj",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "h=rnn.fit(XRNN,Y,validation_split=0.30, epochs=100,batch_size=5)\n",
        "#En cada época nos dice el error que va cometiendo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp9q8fWerORA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#Vemos que funciona bien el test. El train empieza mal pero luego bien. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8d-FyYxZUf"
      },
      "source": [
        "## Utilizar la red:\n",
        "Utilizar el perceptron aprendido con el método [**predict**](https://keras.io/api/models/model_training_apis/#predict-method)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRzCvdbZwZ6k"
      },
      "outputs": [],
      "source": [
        "Y0=rnn.predict(XRNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Unxa4WnnwoFo"
      },
      "outputs": [],
      "source": [
        "r=pd.DataFrame(Y)\n",
        "r['RNN']=pd.DataFrame(Y0)\n",
        "r.plot(figsize=(15,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La diferencia conceptual entre percepton y este, es que el perceptron no tiene memoria, no tiene datos del pasado, sólo tiene lo que le hemos metido. Mientras que las redes neuronales recurrentes sí tienen concepto de pasado. De hecho, se lo pasan a la siguiente etapa. \n",
        "\n",
        "La red neronal recurrente utiliza lo mismo que perceptron pero el aquí el backd. tiene problemas. Debido a esto, se tiene que empezar a hacer cosas como la normalización para solventar esto. Como por ej: Batch - normalización -> normaliza todos los datos a trabajar a partir de ese bacht. Este trabaja con 0 y 1)."
      ],
      "metadata": {
        "id": "qMNz9DVZ_wwp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PxjNviiy-W1"
      },
      "source": [
        "## Salvar y Cargar Redes:\n",
        "- Salvar mediante el método [**save**](https://keras.io/api/models/model_saving_apis/#save-method).\n",
        "- Recuperar un modelo con el método [**load_model**](keras.models.load_model).\n",
        "\n",
        "(Guardamos la red)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4lQ3vSOzGCx"
      },
      "outputs": [],
      "source": [
        "rnn.save('rnn.h5')\n",
        "rnn2=keras.models.load_model('rnn.h5')"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "NN",
      "language": "python",
      "name": "nn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}